In-context function estimation is the task of estimating the underlying function given a set of context points that have been sampled from that function or an empirical process. Using the estimated function, it is possible to impute missing data points. \cite{seifner2025zeroshotimputationfoundationinference}

This can be done using an underlying model assumption like with linear regression. A polynomial of a certain order is fitted to the given data, determining which parameters fit best to the data. For linear regression, it is assumed that the underlying function can be modeled by a polynomial. The order of this polynomial must be determined in advance. Due to the best-fit approach, linear regression is not able to handle uncertainties that might result from missing data.

\begin{figure*}
	\centering
	\resizebox{0.90\textwidth}{!}{
		\input{figures/plots/GP/63}
		\input{figures/plots/GP/62}
		\input{figures/plots/GP/63_100}
	}
	\caption{Gaussian Process function estimation compared to the target function for four example data frames with varying number of context points (5, 50, 50). Functions have been sampled from a multivariate normal distribution with an RBF kernel, the RBF-Scale is given on the top of each plot. }
	\label{fig:gaussian}
\end{figure*}

Gaussian Processes (GP) provide a way of estimating missing values of a function $f(x)$ that takes uncertainties into account. GPs are distributions over functions and we assume a prior distribution of possible underlying functions and update that belief based on the given context points. In practice we are dealing with discrete values, so GPs are defined by a mean value $\mu$ and a covariance matrix. The covariance matrix defines how strongly two values $f(x),f(x')$ vary from each other. Put differently, it defines how much they depend on each other. As we are dealing with 1-d functions, we expect functions values to depend on each other more strongly, the closer the input values are. One way of modelling this behaviour is to use the radial basis function defined in \autoref{eq:rbf}. Each value of the covariance matrix is defined by this equation. Note that $\sigma^2$ is the variance of functions and $l$ is the scaling parameter for all covariance values. Therefore, the lower the value of $l$, the more are the functions in the prior distribution expected to vary over time. \cite{garnelo2018neural, williams2006gaussian}

\begin{align}
k(x,x') &= \sigma^2\text{exp}\left(-\dfrac{(x-x')^2}{2l^2}\right) \label{eq:rbf}
\end{align}

Additionally to defining a prior distribution from which we can draw random functions, we want to update the prior based on context points and get the posterior distribution. This is done by conditioning the prior on the context points. This means removing functions from the prior distribution that do not agree with the context points. For this to be applicable to real data, we need to incorporate noise into the prior distribution. We assume additive Gaussian noise with variance $\sigma_n^2$ and add it to the diagonal of the covariance matrix. \cite{williams2006gaussian}

\autoref{fig:gaussian} shows some results of fitting Gaussian Processes on given context points while knowing the prior distribution from which the true underlying function has been sampled and the standard deviation of the added Gaussian noise. This posterior distribution defines a mean and standard deviation value for each point in the grid. In the leftmost plot, it is visible that missing data from about $x=0.6$ to $x=1$ leads to high uncertainty. As shown in the rightmost plot, we observe spikes and large uncertainty between context points. Specifically, the predicted mean goes to zero (the mean of the prior distribution) between context points. We speculate, that this is due to the low RBF-Scale, which leads to the GP assuming little or no correlation between points that we still consider to be close together. This leads to the posterior distribution reverting to the prior distributions mean of 0 and variance of 1.

For real-world scenarios, we cannot assume to know the prior distribution beforehand. Rather, we want to work with unseen functions directly without any prior knowledge, which inevitably introduces bias. We need to have a model that estimates the underlying function given only some context points and can impute missing values based on that. This in-context zero-shot function estimation can be split up into two subtasks. First, process the context points so that we get a representation of the underlying function and then predict the value of that function at a certain point.

\citet{Lu_2021} train two neural networks for their DeepONet, that tackles these subtasks. The Branch net learns an operator $G: u\rightarrow G(u)$ with $u$ being the sequence of context points and the result $G(u)$ is supposed to represent the underlying function. Using this representation and given an arbitrary point $y$, the Trunk net predicts the value $G(u)(y)$. \cite{Lu_2021}

Neural networks are not well fit to handle sequences of varying length, as we expect with the sequence of context points having a different length depending on the specific use case. \citet{seifner2025zeroshotimputationfoundationinference} use a bi-directional LSTM that acts like the Branch net from DeepONets and allows processing sequences of varying length. 

Adapting their approach, we use a transformer to model sequences of varying length. Transformer rely on the attention mechanism, introduced in \citet{vaswani2017attention}. As the name suggests, the attention mechanism enables models to focus their attention on inputs that are of particular importance. For this, three versions of the input called query, key and value are used. All three versions have their own set of weights for an initial linear projection. The query and key are matrix multiplied, effectively calculating the inner product between each element of the sequence. This can be interpreted as an similarity metric. The result of that matrix multiplication is scaled and normalized by the softmax function, resulting in a weight matrix of the same size as the original input. This weight matrix is applied to the values version of the input. So in essence elements of the input sequence that are similar to many other elements will be weighted higher than other elements. Crucially, the model can learn to adjust what exactly determines the similarity of two elements in the sequence, resulting in the learnable self-attention mechanism. This self attention is then performed multiple times independently in a certain number of attention heads, enabling the model to focus its attention on different things at the same time. \cite{vaswani2017attention}